{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Outputs\n",
    "\n",
    "Previously, you have learnt how to train a model and how to use it for predictions. While that is essential in any data science project, it is not sufficient to just train a model and use it for predictions. This is because even though the model has been trained, we did not evaluate its performance.\n",
    "\n",
    "The model has to be evaluated against data that was not used to train the model. This is because while the model may perform very well with data that it has trained with, it may not be useful if the model is not able to be used for data that it was not trained with. Thus, in this notebook, we will also learn how to ensure that this does not happen. Before we do so, we have to first understand why a model can perform poorly to unseen data even after training. This could be due to either underfitting or overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Underfitting Vs Overfitting\n",
    "\n",
    "Underfitting means that the model is too simplified to be able to explain the data. For example, if you have data that has a non-linear relationship but you are using a linear model to train on, you may suffer from underfitting. This is because the linear model will not be able to explain the non-linear relationship or trend that is observed in the data. Thus, when you use an underfitted model to predict, it will perform poorly.\n",
    "\n",
    "On the other hand, overfitting means that the model is fitted so well that it has also learnt all the noise or outliers within the dataset. As such, it can perform very well when you test it against data that it has been trained with. However, because it is so well trained, it will not be able to generalise and thus, will not perform well when you are testing it against data that it was not trained with.\n",
    "\n",
    "Read this [article](https://medium.com/greyatom/what-is-underfitting-and-overfitting-in-machine-learning-and-how-to-deal-with-it-6803a989c76) and this [article](https://towardsdatascience.com/understanding-the-bias-variance-tradeoff-165e6942b229) for more information about underfitting and overfitting and note down any interesting information in the cell below. While there may be some mathematical equations within the articles, it is ok if you are not able to understand the equations. It is more important to understand the underlying concepts. What is the difference between bias and variance? How do you prevent underfitting? How do you prevent overfitting?\n",
    "\n",
    "Look at the figures below. If the red line were to be your model and the blue points are the dataset, would the model be overfitting or underfitting?\n",
    "\n",
    "![Underfit](assets/model1.jpg)\n",
    "\n",
    "The image above is an example of on underfitted model\n",
    "\n",
    "![Overfit](assets/model2.jpg)\n",
    "\n",
    "The image above is an example of an overfitted model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance between underfitting and overfitting\n",
    "\n",
    "We can see from above that it is important to try and find a balance between underfitting and overfitting. This will allow the model to be accurate but still be able to generalise or perform well on data that it has not been trained in. This means that the model has to be somewhat complex but not too complex. As such, there are some ways that we can try to achieve the balance. We will try some of these methods for the different machine learning techniques that were explored earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbour\n",
    "\n",
    "In an earlier notebook, we learnt how to apply the K-Nearest Neighbour (KNN) algorithm to classify data. As a recap, KNN classifies data points based on the majority of the other points that are closest to the point in question. However, in order to use the algorithm, there was a need to input the number of neighbours as a parameter. In the case of underfitting and overfitting, the number of neighbours do play an important role. This is because the number of neighbours determine how likely the model will overfit. The higher the number of neighbours, the less likely the model will overfit. If the number of neighbours is too high, it will be likely for the model to underfit. Thus, there should be some number in between the two extreme numbers that will allow the model to be relatively balanced. This number will differ for different datasets. We will now try to find this number for the Iris Flower dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width   Class\n",
       "0           5.1          3.5           1.4          0.2  Setosa\n",
       "1           4.9          3.0           1.4          0.2  Setosa\n",
       "2           4.7          3.2           1.3          0.2  Setosa\n",
       "3           4.6          3.1           1.5          0.2  Setosa\n",
       "4           5.0          3.6           1.4          0.2  Setosa"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"datasets/iris.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.843333</td>\n",
       "      <td>3.057333</td>\n",
       "      <td>3.758000</td>\n",
       "      <td>1.199333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.828066</td>\n",
       "      <td>0.435866</td>\n",
       "      <td>1.765298</td>\n",
       "      <td>0.762238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.300000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>1.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.400000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>1.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sepal_length  sepal_width  petal_length  petal_width\n",
       "count    150.000000   150.000000    150.000000   150.000000\n",
       "mean       5.843333     3.057333      3.758000     1.199333\n",
       "std        0.828066     0.435866      1.765298     0.762238\n",
       "min        4.300000     2.000000      1.000000     0.100000\n",
       "25%        5.100000     2.800000      1.600000     0.300000\n",
       "50%        5.800000     3.000000      4.350000     1.300000\n",
       "75%        6.400000     3.300000      5.100000     1.800000\n",
       "max        7.900000     4.400000      6.900000     2.500000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, perform the necessary steps that are required to prepare the data to be processed by a machine learning algroithm. First, extract the features as ``x_values`` and the target variable as ``y_values``. In this case, the ``x_values`` will be \"sepal_length\", \"sepal_width\", \"petal_length\" and \"petal_width\" whereas the ``y_values`` will be the class. Additionally, remmeber to label encode the ``y_values``. You can encode \"Setosa\" as 0, \"Versicolor\" as 1 and \"Virginica\" as 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    50\n",
      "2    50\n",
      "3    50\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# dictionary to map class to number\n",
    "class_to_num = {\"Class\" : {'Setosa': 1, 'Versicolor': 2, 'Virginica': 3}}\n",
    "\n",
    "# use replace function to map class to number\n",
    "df.replace(class_to_num, inplace=True)\n",
    "print(df[\"Class\"].value_counts())\n",
    "\n",
    "x_values = df.drop([\"Class\"], axis=1)\n",
    "y_values = df[\"Class\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we are assurred that the data is ready to be processed by a machine learning model, we can now focus on how to balance the overfitting and underfitting issue.\n",
    "\n",
    "If we want to determine this balance, we will need to be able to evaluate how well the model will perform or how accuracte the model will be if the model were to be applied to data that it has not been trained with. As we do not have future data, we will need to be able to use the current data to perform this evaluation. As such, the current dataset is usually split into 2 different groups. One group will contain all the training data which will be used to train the data. On the other hand, the other group will contain test data that will not be seen or used in the model training phase. The test data will serve as \"future\" data which will be used to evaluate the model.\n",
    "\n",
    "In order to split the data into 2 groups, we will use the ``train_test_split`` function from ``sklearn.model_selection``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_values,y_values,test_size=0.25,random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After splitting the data, we now have to standardise or normalise the data. It is always good practice to standardise or normalise any dataset that you use for machine learning. This will help scale the values for all the variables or features into similar ranges. Always remember to conduct the standardisation or normalisation after the data has been split. This is to ensure that the test dataset will always remain unseen by the model and not used in the normalisation or standardisation process of the training data.\n",
    "\n",
    "In this case, we will choose to use ``StandardScaler`` from ``sklearn.preprocessin``g to standardise the data. Remember to apply the ``.fit_transform`` method to the ``x_train`` data values but only the ``.transform`` method to the ``x_test`` data. Create a variable called ``x_train_scale`` for the train data after standardisation and create another variable called ``x_test_scale`` for the test data after standardisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train_scale = scaler.fit_transform(x_train)\n",
    "x_test_scale = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After standardising the data, we can now implement a way to find the optimal number of neighbours for the KNN algorithm. To do so, we will train the KNN algorithm with differnt number of neighbours and also evaluate against the test data. By doing so, we will be able to obtain the accuracy of the KNN model for different number of neighbours. We can then find the number of neighbours that correspond to the highest accuracy. That number will be the optimal number of neighbours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9736842105263158, 0.9736842105263158, 0.9736842105263158, 0.9736842105263158, 0.9736842105263158, 1.0, 0.9473684210526315, 0.9473684210526315, 0.9473684210526315, 0.9736842105263158, 0.9736842105263158, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "# Create an empty list to store the accuracy and number of neighbours for each KNN model\n",
    "accuracy = []\n",
    "num_neigh = []\n",
    "\n",
    "# Use ii to cycle through values 1 to 15. This will be the number of neighbours for the KNN classifier. \n",
    "for ii in range(1,16):\n",
    "    # Set number of neighbours to ii\n",
    "    KNN = KNeighborsClassifier(n_neighbors=ii)\n",
    "    # Training or fitting the model with the data\n",
    "    KNN.fit(x_train_scale,y_train)\n",
    "    # .score provides the accuracy of the model based on the testing data. Store the accuracy into the list.\n",
    "    accuracy.append(KNN.score(x_test_scale,y_test))\n",
    "    # Append the number of neighbours to a list\n",
    "    num_neigh.append(ii)\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us plot the accuracy values on the graph to help us determine the optimal number of neighbours. Try the code below! Remember to import matplotlib.pyplot as plt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(num_neigh,accuracy)\n",
    "plt.xlabel('Number of neighbours')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the graph above, which will be the optimal number of neighbours to use? The optimal number of neighbours is 6. It has the lowest number of neighbours out of all the points with the highest accuracy values.\n",
    "\n",
    "What we have essentially done now is a form of hyperparameter tuning, here number of neighbours is a hyperparameter that can be set by us and we tried to find the most optimal hyperparameter. \n",
    "\n",
    "This technique can be applied to other types of models too!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
