# Week 3 - Advanced Classification Models

Last Week we went throught data visualization techniques and data preprocessing and we also did a simple binary classification task.

In this week, we will explore advanced classification models such as KNN (K-Nearest Neighbors), Naive Bayes, Decision Trees, and Random Forests. These algorithms are widely used in machine learning for classification tasks.

**KNN (K-Nearest Neighbors):**
KNN is a non-parametric algorithm that classifies new data points based on their proximity to existing data points. It assigns a class label to a new data point based on the majority class of its k nearest neighbors.

**Naive Bayes:**
Naive Bayes is a probabilistic algorithm that applies Bayes' theorem with the assumption of independence between features. It calculates the probability of a data point belonging to a particular class based on the probabilities of its features.

**Decision Trees:**
Decision Trees are a popular algorithm for both classification and regression tasks. They create a tree-like model of decisions and their possible consequences. Each internal node represents a feature, each branch represents a decision rule, and each leaf node represents the outcome.

**Random Forests:**
Random Forests is an ensemble learning method that combines multiple decision trees to make predictions. It creates a set of decision trees and aggregates their predictions to obtain the final result. This technique improves the accuracy and robustness of the model.

**Model Outputs:**
After training a classification model, we can use it to make predictions on new, unseen data. The model outputs the predicted class labels for the input data points. These predicted labels can be used for various purposes, such as making business decisions or further analysis.

**Overfitting and Underfitting:**
When training a classification model, it is important to find the right balance between overfitting and underfitting. Overfitting occurs when the model learns the training data too well and performs poorly on new, unseen data. Underfitting, on the other hand, occurs when the model is too simple and fails to capture the underlying patterns in the data.

In this module, we will dive deep into the working principles, advantages, and limitations of these advanced classification models. We will also discuss how to train and evaluate these models using real-world datasets.

Let's get started with advanced classification models and take our machine learning skills to the next level!

Note that we won't be talking much about the math behind the algorithms, rather we will look at it's implementation with the help of libraries.
